1+2
2+3
1+2+3+4+5
Hello World
print("Hello World")
print(Hello World)
print("Hello World)
print("Hello World")
A <- 1+2
A
library(help="base")
A <- 1+2
A
library(help="base")
X <- c(100, 200, 300)
mean(X)
answer
z <- 10 < 200
z
answer <- 10 < 200
answer
getwd
getwd)()
getwd()
install.packages("stringr")
install.packages("ggplot2")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("stringr")
install.packages("ggplot2")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME=('C:\\Program Files\\Java\\jdk-11.0.2')
library("KoNLP")
useSejongDic()
mergeUserDic(data.frame("한민아","ncn"))
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME=('C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
mergeUserDic(data.frame("한민아","ncn"))
install.packages("stringr")
install.packages("ggplot2")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME=('C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
mergeUserDic(data.frame("한민아","ncn"))
install.packages("stringr")
install.packages("ggplot2")
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
mergeUserDic(data.frame("한민아","ncn"))
library("stringr")
library("ggplot2")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
setwd("C:\Users\ChoRong\Desktop\거위")
install.packages("stringr")
install.packages("stringr")
install.packages("stringr")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","") # 특수문자
text <- str_replace_all(text,"[A-Za-z0-9]","")  # 숫자
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
text_table <- read.table("kr_text.txt")
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
setwd("C:\\Users\\ChoRong\\Desktop\\거위")
text <- readLines("review.txt")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","") # 특수문자
text <- str_replace_all(text,"[A-Za-z0-9]","")  # 숫자
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
setwd("C:\\Users\\ChoRong\\Desktop\\거위")
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","") # 특수문자
text <- str_replace_all(text,"[A-Za-z0-9]","")  # 숫자
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","") # 특수문자
text <- str_replace_all(text,"[A-Za-z0-9]","")  # 숫자
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
display.brewer.all()
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
