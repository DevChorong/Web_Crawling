# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
# Register nouns
mergeUserDic(data.frame("가", "ncn"))
useSejongDic()
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("stringr")
install.packages("ggplot2")
install.packages("SnowballC")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
install.packages("SnowballC")
# import 한 패키지들 사용
library("SnowballC")
library("wordcloud")
library("plyr")
library("stringr")
library("ggplot2")
# Register nouns
mergeUserDic(data.frame("가", "ncn"))
mergeUserDic(data.frame("가", "ncn"))
mergeUserDic(data.frame("나", "ncn"))
mergeUserDic(data.frame("다", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = FALSE, colors=brewer.pal(8, "Dark2"))
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
mergeUserDic(data.frame("영화", "ncn"))
mergeUserDic(data.frame("재미", "ncn"))
mergeUserDic(data.frame("크롤", "ncn"))
mergeUserDic(data.frame("홍길동", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
# 가장 중요한 한글 체킹 패키지
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
mergeUserDic(data.frame("홍길동", "ncn"))
mergeUserDic(data.frame("김철수", "ncn"))
mergeUserDic(data.frame("박영희", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
library("KoNLP")
useSejongDic()
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
# Register nouns
mergeUserDic(data.frame("홍길동", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = FALSE, colors=brewer.pal(8, "Dark2"))
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
# Register nouns
mergeUserDic(data.frame("word", "frq"))
# Register nouns
mergeUserDic(data.frame("한글", "트분동"))
# Register nouns
mergeUserDic(data.frame("한글", "ncn"))
# Register nouns
mergeUserDic(data.frame("트분동", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8, "Dark2"))
wordcloud(words=terms$word, freq=terms$freq, random.order = T, colors=brewer.pal(8, "Dark2"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8, "Dark2"))
help("mergeUserDic")
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름")
"ncn"
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름", "ncn")
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름"))
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름"))
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름", "ncn"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8, "Dark2"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text
text <- unlist(text)
text
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터
text
text <- Filter(function(x) {nchar(x) >= 2}, text)
text
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text
text <- Filter(function(x) {nchar(x) >= 2}, text)
text
text
max.print(text)
text.max
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
# Textfile 가져오기
text <- readLines("review.txt")
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 1}, text)
text
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8, "Dark2"))
text_table
word_count
terms
word_count
term
terms
# 정렬 해주기
terms <- arrange(terms, desc(freq))
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
terms
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자이름", "ncn"))
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
text
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
text_table
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
word_count
# dataFrame 만들기
terms <- data.frame(word_count)
terms
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
terms
# 정렬 해주기
terms <- arrange(terms, desc(freq))
terms
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8, "Dark2"))
# 가장 중요한 한글 체킹 패키지
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
display.brewer,all()
display.brewerall()
display.brewer_all()
display.brewer.all()
install.packages("plyr")
install.packages("stringr")
install.packages("stringr")
install.packages("ggplot2")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
display.brewer.all()
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사전이름", "ncn"))
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사용자", "ncn"))
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("홍길동", "ncn"))
useSejongDic()
library("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("홍길동", "ncn"))
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사전이름", "ncn"))
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("stringr")
library("ggplot2")
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
# 테이블 형태로 데이터 만들기
word_count <- table(text_table)
# dataFrame 만들기
terms <- data.frame(word_count)
# 열 이름 바꿔주기
names(terms) <- c("word", "freq")
# 정렬 해주기
terms <- arrange(terms, desc(freq))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8,"PuBu"))
display.brewer.all()
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(8,"RbGy"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(10,"RbGy"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
wordcloud(words=terms$word, freq=terms$freq, random.order = F, colors=brewer.pal(12,"Paired"))
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사전이름", "ncn"))
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("stringr")
install.packages("ggplot2")
install.packages("stringr")
mergeUserDic(data.frame("사전이름", "ncn"))
install.packages("KoNLP")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
library("KoNLP")
useSejongDic()
# 사용자이름 에 해당하는 data.frame의 사전을 하나 생성한다.
mergeUserDic(data.frame("사전이름", "ncn"))
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("plyr")
install.packages("ggplot2")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("plyr")
library("ggplot2")
setwd("C:\\Users\\ChoRong\\Desktop\\Base\\04. 개인 연구\\[4]Web_Crawling")
# Textfile 가져오기
text <- readLines("review.txt")
# 명사 단위로 쪼개기
text <- sapply(text, extractNoun, USE.NAMES = F)
# 리스트 해제 하고 2개의 길이만 허용하는 필터 = [1차원 형태로 만듦]
text <- unlist(text)
text <- Filter(function(x) {nchar(x) >= 2}, text)
# 필요없는 단어 삭제하기
text <- str_replace_all(text,"[^[:alpha:]]","")
text <- str_replace_all(text,"[A-Za-z0-9]","")
text <- gsub("을", "", text)
text <- gsub("를", "", text)
text <- gsub("ㅋ", "", text)
text <- gsub("ㅠ", "", text)
text <- gsub("ㅇ", "", text)
text <- gsub("영화", "", text)
# 임시적인 파일을 만들어서 테이블 형태로 불러오기.
write(unlist(text) , "kr_text.txt")
text_table <- read.table("kr_text.txt")
install.packages("stringr")
install.packages("stringr")
